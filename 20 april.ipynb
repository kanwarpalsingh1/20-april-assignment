{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7ff747-594c-4a11-8a24-784c2f8d646b",
   "metadata": {},
   "source": [
    "Q1.\n",
    "ans:-The KNN (K-Nearest Neighbors) algorithm is a non-parametric, lazy learning algorithm used for classification and regression tasks in machine learning. It makes predictions by identifying the K nearest data points in the training set to a given input data point and then averaging the labels of those data points for classification or averaging their values for regression.\n",
    "\n",
    "Q2.\n",
    "ans:-The value of K in KNN is typically chosen empirically through techniques such as cross-validation. A smaller value of K may result in a more flexible model with potentially higher variance and lower bias, while a larger value of K may lead to a smoother decision boundary with lower variance but potentially higher bias.\n",
    "\n",
    "Q3. \n",
    "ans:-The main difference between KNN classifier and KNN regressor lies in their prediction tasks. KNN classifier predicts the class label of a new data point based on the majority class among its K nearest neighbors, while KNN regressor predicts the numerical value of a new data point by averaging the values of its K nearest neighbors.\n",
    "\n",
    "Q4.\n",
    "ans:-The performance of KNN can be measured using various evaluation metrics such as accuracy, precision, recall, F1-score for classification tasks, and metrics like mean squared error (MSE) or R-squared for regression tasks.\n",
    "\n",
    "Q5.\n",
    "ans:-The curse of dimensionality refers to the phenomenon where the feature space becomes increasingly sparse as the number of dimensions (features) increases. In KNN, this can lead to a significant increase in computational complexity and the risk of overfitting due to the sparsity of the data.\n",
    "\n",
    "Q6.\n",
    "ans:-In KNN, missing values can be handled by either imputing them with the mean, median, or mode of the feature values or by using techniques such as mean imputation based on nearest neighbors.\n",
    "\n",
    "Q7.\n",
    "ans:The performance of the KNN classifier and regressor depends on the nature of the problem and the characteristics of the dataset. In general, the KNN classifier is better suited for classification problems where decision boundaries are complex and non-linear, while the KNN regressor is suitable for regression tasks where the relationship between features and target variable is non-linear.\n",
    "\n",
    "Q8.\n",
    "\n",
    "Strengths:\n",
    "Simple to understand and implement.\n",
    "Does not assume any underlying distribution of the data.\n",
    "Effective for non-linear relationships between features and target variable.\n",
    "Weaknesses:\n",
    "Computationally expensive for large datasets and high-dimensional feature spaces.\n",
    "Sensitive to irrelevant and redundant features.\n",
    "Performance can deteriorate with noisy data and imbalanced class distributions.\n",
    "These weaknesses can be addressed by using dimensionality reduction techniques, feature selection methods, and model optimization techniques.\n",
    "\n",
    "Q9\n",
    "ans:-. Euclidean distance measures the straight-line distance between two points in Euclidean space, while Manhattan distance (also known as city block distance) measures the distance between two points along the axis-aligned paths formed by the grid of streets in a city.\n",
    "\n",
    "Q10.\n",
    "ans:-Feature scaling is important in KNN to ensure that all features contribute equally to the distance calculations. Without feature scaling, features with larger scales or magnitudes may dominate the distance metric, leading to biased results. Common scaling techniques include standardization (scaling features to have zero mean and unit variance) and normalization (scaling features to a fixed range, such as [0, 1]).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
